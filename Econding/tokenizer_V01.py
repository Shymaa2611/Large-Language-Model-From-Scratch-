import re
import urllib.request

"""
Tokenizer Step
text ---> tokens ----> tokens ids

"""
class Tokenizer:
    def __init__(self,vocab):
        self.str_to_int=vocab
        self.int_to_str={i:s for s,i in vocab.items()}

    def encode(self,text):
      preprocessed=re.split(r'([,.?_!"()\']|--|/s)',text)
      preprocessed=[
         item.strip() for item in preprocessed if item.strip()
      ]
      ids = [self.str_to_int[s] for s in preprocessed]
      return ids

def main(text):
    url = (
    "https://raw.githubusercontent.com/rasbt/"
    "LLMs-from-scratch/main/ch02/01_main-chapter-code/"
    "the-verdict.txt"
)
    file_path="the-verdict.txt"
    urllib.request.urlretrieve(url,file_path)
    with open("the-verdict.txt","r",encoding="utf-8") as f:
        raw_text=f.read()
    preprocessed=re.split(r'([,.?_!"()\']|--|/s)',raw_text)
    preprocessed=[item.strip() for item in preprocessed if item.strip()]
    all_words=sorted(set(preprocessed))
    vocab={token:id for id,token in enumerate(all_words)}
    tokenizer=Tokenizer(vocab)
    ids=tokenizer.encode(text)
    print(ids)

   
if __name__: 
   text="It's the last he painted , you know" 
   main(text)